Local LLM-Powered Coding Assistant Project

This project aims to create a command-line coding assistant that leverages local language models running on Ollama. The assistant will function similarly to Claude Code but will operate entirely locally for personal development use.

Key Specifications:
- Core implementation in Python 3
- Integration with Ollama for local model hosting and inference
- Command-line interface for developer interaction
- Specialized focus on Godot 4 game development
- Support for GDScript syntax highlighting and code completion
- Ability to understand and generate code that follows Godot 4's node-based architecture
- Knowledge of Godot 4's built-in classes, methods, and design patterns
- Capability to assist with both 2D and 3D game implementation
- Support for debugging common Godot-specific issues

The primary use case will be assisting in game development projects using the Godot 4 engine, including generating code snippets, explaining engine concepts, suggesting optimizations, and helping implement game mechanics following Godot best practices.
